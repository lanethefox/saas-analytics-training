#!/usr/bin/env python3
"""
Complete Superset setup script
- Creates database connection
- Sets up all datasets
- Creates sample charts
- Configures permissions
"""

import requests
import json
import time
from typing import Dict, List, Optional
import sys

# Superset configuration
SUPERSET_URL = "http://localhost:8088"
USERNAME = "admin"
PASSWORD = "admin_password_2024"

# PostgreSQL configuration
PG_HOST = "postgres"  # Docker service name
PG_PORT = 5432
PG_DATABASE = "saas_platform_dev"
PG_USERNAME = "saas_user"
PG_PASSWORD = "saas_secure_password_2024"

class SupersetSetupManager:
    def __init__(self):
        self.session = requests.Session()
        self.csrf_token = None
        self.access_token = None
        self.database_id = None
        
    def get_csrf_token(self):
        """Get CSRF token from Superset"""
        try:
            # Try the new API endpoint first
            response = self.session.get(f"{SUPERSET_URL}/api/v1/security/csrf_token/")
            if response.status_code == 200:
                self.csrf_token = response.json()['result']
                self.session.headers.update({'X-CSRFToken': self.csrf_token})
                return True
            
            # Try alternative method - get from login page
            response = self.session.get(f"{SUPERSET_URL}/login/")
            if response.status_code == 200:
                # Extract CSRF token from HTML if needed
                # For now, we'll proceed without it as login might not require it
                print("  â†’ Proceeding without explicit CSRF token")
                return True
                
        except Exception as e:
            print(f"Error getting CSRF token: {e}")
        return False
    
    def login(self):
        """Login to Superset using the API"""
        login_data = {
            "username": USERNAME,
            "password": PASSWORD,
            "provider": "db",
            "refresh": True
        }
        
        try:
            response = self.session.post(
                f"{SUPERSET_URL}/api/v1/security/login",
                json=login_data,
                headers={"Content-Type": "application/json"}
            )
            
            if response.status_code == 200:
                tokens = response.json()
                self.access_token = tokens['access_token']
                self.session.headers.update({
                    'Authorization': f'Bearer {self.access_token}',
                    'Content-Type': 'application/json'
                })
                print("âœ“ Successfully logged in to Superset")
                return True
            else:
                print(f"âœ— Failed to login: {response.status_code}")
                print(f"Response: {response.text}")
        except Exception as e:
            print(f"Error during login: {e}")
        return False
    
    def setup_database_connection(self):
        """Create or update PostgreSQL database connection"""
        print("\n=== Setting up Database Connection ===")
        
        # Check if database already exists
        response = self.session.get(f"{SUPERSET_URL}/api/v1/database/")
        
        existing_db_id = None
        if response.status_code == 200:
            databases = response.json()
            for db in databases.get('result', []):
                if PG_DATABASE in db.get('database_name', ''):
                    existing_db_id = db['id']
                    print(f"  â†’ Found existing database connection (ID: {existing_db_id})")
                    self.database_id = existing_db_id
                    return True
        
        # Create new database connection
        database_data = {
            "database_name": "SaaS Platform PostgreSQL",
            "sqlalchemy_uri": f"postgresql://{PG_USERNAME}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DATABASE}",
            "expose_in_sqllab": True,
            "allow_ctas": True,
            "allow_cvas": True,
            "allow_dml": True,
            "allow_run_async": True,
            "cache_timeout": 300,
            "extra": json.dumps({
                "metadata_params": {},
                "engine_params": {
                    "pool_size": 50,
                    "max_overflow": 100,
                    "pool_pre_ping": True,
                    "pool_recycle": 3600
                },
                "metadata_cache_timeout": {},
                "schemas_allowed_for_file_upload": ["public", "staging", "mart", "entity"]
            }),
            "impersonate_user": False,
            "allow_multi_schema_metadata_fetch": True,
            "parameters": {
                "host": PG_HOST,
                "port": PG_PORT,
                "database": PG_DATABASE,
                "username": PG_USERNAME,
                "password": PG_PASSWORD
            }
        }
        
        response = self.session.post(
            f"{SUPERSET_URL}/api/v1/database/",
            json=database_data
        )
        
        if response.status_code in [200, 201]:
            self.database_id = response.json()['result']['id']
            print(f"âœ“ Created database connection (ID: {self.database_id})")
            
            # Test connection
            self.test_database_connection()
            return True
        else:
            print(f"âœ— Failed to create database: {response.status_code}")
            print(f"Response: {response.text}")
            return False
    
    def test_database_connection(self):
        """Test the database connection"""
        response = self.session.post(
            f"{SUPERSET_URL}/api/v1/database/{self.database_id}/test_connection/"
        )
        
        if response.status_code == 200:
            print("  â†’ Database connection test successful")
        else:
            print(f"  â†’ Database connection test failed: {response.status_code}")
    
    def create_dataset(self, schema: str, table_name: str, description: str = "") -> Optional[int]:
        """Create a dataset in Superset"""
        # Check if dataset already exists
        check_response = self.session.get(
            f"{SUPERSET_URL}/api/v1/dataset/",
            params={
                "q": json.dumps({
                    "filters": [
                        {"col": "table_name", "opr": "eq", "value": table_name},
                        {"col": "schema", "opr": "eq", "value": schema}
                    ]
                })
            }
        )
        
        if check_response.status_code == 200:
            result = check_response.json()
            if result['count'] > 0:
                dataset_id = result['result'][0]['id']
                print(f"  â†’ Dataset exists: {schema}.{table_name} (ID: {dataset_id})")
                return dataset_id
        
        # Create new dataset
        dataset_data = {
            "database": self.database_id,
            "schema": schema,
            "table_name": table_name,
            "description": description
        }
        
        response = self.session.post(
            f"{SUPERSET_URL}/api/v1/dataset/",
            json=dataset_data
        )
        
        if response.status_code in [200, 201]:
            result = response.json()
            dataset_id = result.get('id') or result.get('result', {}).get('id')
            print(f"âœ“ Created dataset: {schema}.{table_name} (ID: {dataset_id})")
            return dataset_id
        else:
            print(f"âœ— Failed to create dataset {schema}.{table_name}: {response.status_code}")
            return None
    
    def setup_all_datasets(self):
        """Create all datasets for dashboards"""
        print("\n=== Setting up Datasets ===")
        
        # Core datasets needed for all dashboards
        core_datasets = [
            # Universal metrics
            ("public", "metrics_unified", "Combined metrics from all domains"),
            ("public", "metrics_company_overview", "Executive-level rollups"),
            
            # Sales datasets
            ("public", "metrics_sales", "Sales team KPIs"),
            ("mart", "mart_sales__pipeline", "Sales pipeline details"),
            
            # Customer Success datasets
            ("public", "metrics_customer_success", "Customer health metrics"),
            ("entity", "entity_customers", "Customer master data"),
            ("entity", "entity_customers_daily", "Daily customer metrics"),
            
            # Marketing datasets
            ("public", "metrics_marketing", "Marketing performance metrics"),
            ("entity", "entity_campaigns", "Campaign data"),
            ("mart", "mart_marketing__attribution", "Attribution analysis"),
            
            # Product datasets
            ("public", "metrics_product_analytics", "Product usage metrics"),
            ("public", "metrics_engagement", "User engagement metrics"),
            ("entity", "entity_users", "User data"),
            ("entity", "entity_features", "Feature adoption"),
            
            # Operations datasets
            ("public", "metrics_operations", "Operational metrics"),
            ("public", "metrics_revenue", "Revenue metrics"),
            ("entity", "entity_devices", "Device data"),
            
            # Additional useful datasets
            ("marketing", "marketing_qualified_leads", "MQL data"),
            ("raw", "accounts", "Raw account data"),
            ("raw", "users", "Raw user data"),
        ]
        
        created_count = 0
        for schema, table, description in core_datasets:
            dataset_id = self.create_dataset(schema, table, description)
            if dataset_id:
                created_count += 1
            time.sleep(0.3)  # Rate limiting
        
        print(f"\nâœ“ Created/verified {created_count} datasets")
        return created_count
    
    def create_sample_chart(self):
        """Create a sample chart to verify setup"""
        print("\n=== Creating Sample Chart ===")
        
        # Get metrics_sales dataset ID
        response = self.session.get(
            f"{SUPERSET_URL}/api/v1/dataset/",
            params={
                "q": json.dumps({
                    "filters": [
                        {"col": "table_name", "opr": "eq", "value": "metrics_sales"}
                    ]
                })
            }
        )
        
        if response.status_code != 200 or response.json()['count'] == 0:
            print("âœ— Could not find metrics_sales dataset")
            return
        
        dataset_id = response.json()['result'][0]['id']
        
        # Create a simple KPI chart
        chart_data = {
            "slice_name": "Total Revenue (Sample)",
            "viz_type": "big_number_total",
            "datasource_id": dataset_id,
            "datasource_type": "table",
            "params": json.dumps({
                "datasource": f"{dataset_id}__table",
                "viz_type": "big_number_total",
                "metric": {
                    "aggregate": "SUM",
                    "column": {
                        "column_name": "total_revenue",
                        "type": "DOUBLE PRECISION"
                    },
                    "expressionType": "SIMPLE",
                    "label": "Total Revenue"
                },
                "adhoc_filters": [],
                "header_font_size": 0.4,
                "subheader_font_size": 0.15,
                "y_axis_format": "$,.0f",
                "time_range": "No filter"
            }),
            "description": "Sample KPI chart showing total revenue"
        }
        
        response = self.session.post(
            f"{SUPERSET_URL}/api/v1/chart/",
            json=chart_data
        )
        
        if response.status_code in [200, 201]:
            chart_id = response.json().get('id') or response.json().get('result', {}).get('id')
            print(f"âœ“ Created sample chart (ID: {chart_id})")
            print(f"  View it at: {SUPERSET_URL}/superset/explore/?slice_id={chart_id}")
        else:
            print(f"âœ— Failed to create chart: {response.status_code}")

def check_superset_availability():
    """Check if Superset is running and accessible"""
    try:
        response = requests.get(f"{SUPERSET_URL}/health")
        if response.status_code == 200:
            print("âœ“ Superset is running")
            return True
    except Exception as e:
        print(f"âœ— Cannot connect to Superset at {SUPERSET_URL}")
        print(f"  Error: {e}")
        print("\nMake sure Superset is running:")
        print("  docker-compose up -d superset")
    return False

def main():
    print("=== Superset Complete Setup ===\n")
    
    # Check if Superset is available
    if not check_superset_availability():
        return
    
    # Initialize setup manager
    manager = SupersetSetupManager()
    
    # Get CSRF token
    if not manager.get_csrf_token():
        print("Failed to get CSRF token")
        return
    
    # Login to Superset
    if not manager.login():
        print("Failed to login to Superset")
        print("\nTroubleshooting:")
        print("1. Check Superset is running: docker-compose ps")
        print("2. Verify credentials in docker-compose.yml")
        print("3. Try accessing Superset UI manually first")
        return
    
    # Setup database connection
    if not manager.setup_database_connection():
        print("Failed to setup database connection")
        return
    
    # Create all datasets
    dataset_count = manager.setup_all_datasets()
    
    # Create a sample chart
    manager.create_sample_chart()
    
    print("\n\nðŸŽ‰ Superset setup complete!")
    print(f"\nSummary:")
    print(f"- Database connection: âœ“")
    print(f"- Datasets created: {dataset_count}")
    print(f"- Sample chart: âœ“")
    print(f"\nAccess Superset at: {SUPERSET_URL}")
    print(f"Login with: {USERNAME} / {PASSWORD}")
    print(f"\nNext steps:")
    print("1. Navigate to Data â†’ Datasets to see all tables")
    print("2. Create charts for each dashboard")
    print("3. Assemble charts into dashboards")
    print("4. Configure filters and refresh schedules")

if __name__ == "__main__":
    main()