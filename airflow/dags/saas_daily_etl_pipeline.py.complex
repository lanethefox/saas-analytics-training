"""
SaaS Data Platform - Daily ETL Pipeline
Orchestrates dbt models and ML feature generation
"""

from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.operators.dummy import DummyOperator
from airflow.sensors.external_task import ExternalTaskSensor
import logging

logger = logging.getLogger(__name__)

# Default arguments
default_args = {
    'owner': 'data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
}

# Create DAG
dag = DAG(
    'saas_daily_etl_pipeline',
    default_args=default_args,
    description='Daily ETL pipeline for SaaS data platform',
    schedule_interval='0 6 * * *',  # Run daily at 6 AM UTC
    catchup=False,
    max_active_runs=1,
    tags=['etl', 'dbt', 'daily']
)

# Start marker
start_pipeline = DummyOperator(
    task_id='start_pipeline',
    dag=dag
)

# dbt source freshness check
dbt_source_freshness = BashOperator(
    task_id='dbt_source_freshness',
    bash_command="""
    cd /opt/dbt_project && 
    dbt source freshness --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run staging models
dbt_run_staging = BashOperator(
    task_id='dbt_run_staging',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:staging --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run intermediate models
dbt_run_intermediate = BashOperator(
    task_id='dbt_run_intermediate',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:intermediate --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run entity models (atomic)
dbt_run_entities_atomic = BashOperator(
    task_id='dbt_run_entities_atomic',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:atomic --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run entity models (history)
dbt_run_entities_history = BashOperator(
    task_id='dbt_run_entities_history',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:history --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run entity models (grain)
dbt_run_entities_grain = BashOperator(
    task_id='dbt_run_entities_grain',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:grain --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt run mart models
dbt_run_marts = BashOperator(
    task_id='dbt_run_marts',
    bash_command="""
    cd /opt/dbt_project && 
    dbt run --select tag:mart --profiles-dir /opt/dbt
    """,
    dag=dag
)

# dbt test all models
dbt_test = BashOperator(
    task_id='dbt_test',
    bash_command="""
    cd /opt/dbt_project && 
    dbt test --profiles-dir /opt/dbt
    """,
    dag=dag
)

# Generate ML features
def generate_ml_features(**context):
    """Generate ML features for model training"""
    import sys
    sys.path.append('/opt/ml')
    
    from ml.features.daily_feature_pipeline import DailyFeaturePipeline
    
    pipeline = DailyFeaturePipeline()
    pipeline.run(execution_date=context['execution_date'])
    
    logger.info("ML features generated successfully")

generate_features = PythonOperator(
    task_id='generate_ml_features',
    python_callable=generate_ml_features,
    dag=dag
)

# Refresh model predictions
refresh_predictions = BashOperator(
    task_id='refresh_ml_predictions',
    bash_command="""
    python /opt/ml/inference/batch_prediction_pipeline.py --date {{ ds }}
    """,
    dag=dag
)

# Data quality checks
def run_data_quality_checks(**context):
    """Run comprehensive data quality checks"""
    import sys
    sys.path.append('/opt/ml')
    
    from ml.monitoring.data_quality_monitor import DataQualityMonitor
    
    monitor = DataQualityMonitor()
    results = monitor.run_daily_checks(execution_date=context['execution_date'])
    
    # Raise alert if critical issues found
    if results['critical_issues'] > 0:
        raise ValueError(f"Critical data quality issues found: {results['critical_issues']}")
    
    logger.info(f"Data quality check completed: {results}")

data_quality_checks = PythonOperator(
    task_id='data_quality_checks',
    python_callable=run_data_quality_checks,
    dag=dag
)

# Model performance monitoring
def monitor_model_performance(**context):
    """Monitor ML model performance and data drift"""
    import sys
    sys.path.append('/opt/ml')
    
    from ml.monitoring.model_monitor import ModelPerformanceMonitor
    
    monitor = ModelPerformanceMonitor()
    results = monitor.run_daily_monitoring(execution_date=context['execution_date'])
    
    logger.info(f"Model monitoring completed: {results}")

model_monitoring = PythonOperator(
    task_id='model_performance_monitoring',
    python_callable=monitor_model_performance,
    dag=dag
)

# Generate documentation
dbt_docs_generate = BashOperator(
    task_id='dbt_docs_generate',
    bash_command="""
    cd /opt/dbt_project && 
    dbt docs generate --profiles-dir /opt/dbt
    """,
    dag=dag
)

# End marker
end_pipeline = DummyOperator(
    task_id='end_pipeline',
    dag=dag
)

# Pipeline dependencies
start_pipeline >> dbt_source_freshness >> dbt_run_staging

dbt_run_staging >> dbt_run_intermediate
dbt_run_intermediate >> dbt_run_entities_atomic

dbt_run_entities_atomic >> [dbt_run_entities_history, dbt_run_entities_grain]
[dbt_run_entities_history, dbt_run_entities_grain] >> dbt_run_marts

dbt_run_marts >> dbt_test
dbt_test >> [generate_features, data_quality_checks]

generate_features >> refresh_predictions
[refresh_predictions, data_quality_checks] >> model_monitoring

model_monitoring >> dbt_docs_generate >> end_pipeline
